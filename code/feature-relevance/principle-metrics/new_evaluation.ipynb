{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The way the new evaluation works is following this simple algorithm:\n",
    "\n",
    "if (sentence contains key words):\n",
    "  We want a compact/'specific' explanation, where only the key words are highlighted\n",
    "else:\n",
    "  We want a general/'nuanced' explanations, where all words have similar relevance\n",
    "\n",
    "\n",
    "How to we check for key words:\n",
    " - fidelity: words that flip the prediction are more likely to be key words\n",
    " - realism: words that are similar to a set of pre-identified key words\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"\"]\n",
    "x = [0]\n",
    "model = lambda x: 0\n",
    "keyWordsClass0 = [] # pre-identified set of key words for class 0\n",
    "keyWordsClass1 = [] # pre-identified set of key words for class 1\n",
    "explanation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realism(sentence, positive_words, negative_words, prediction, num_words):\n",
    "    \"\"\"\n",
    "    sentence: a list of words\n",
    "    positive words: words associated with class 1\n",
    "    negative words: words associated with class 0\n",
    "    prediction: the class of the prediction\n",
    "\n",
    "    returns the indices of the realistic words, if there are any\n",
    "    \"\"\"\n",
    "    keywords = set()\n",
    "    for (i, word) in enumerate(sentence):\n",
    "        if (i >= num_words):\n",
    "            return keywords\n",
    "        if (prediction == 0):\n",
    "            for nw in negative_words:\n",
    "                try:\n",
    "                    if (wn.synsets(word)[0].wup_similarity(wn.synsets(nw)[0]) > 0.75):\n",
    "                        keywords.add((i, word))\n",
    "                except:\n",
    "                    if (word == nw):\n",
    "                        keywords.add((i, word))\n",
    "        if (prediction == 1):\n",
    "            for pw in positive_words:\n",
    "                try:\n",
    "                    if (wn.synsets(word)[0].wup_similarity(wn.synsets(pw)[0]) > 0.75):\n",
    "                        keywords.add((i, word))\n",
    "                except:\n",
    "                    if (word == pw):\n",
    "                        keywords.add((i, word))\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(x, model, num_words):\n",
    "    \"\"\"\n",
    "    x: the input words\n",
    "    model: the prediction model\n",
    "    \"\"\"\n",
    "    keywords = []\n",
    "    samples = 5\n",
    "    for (i, w) in enumerate(x):\n",
    "        if (i >= num_words):\n",
    "            return keywords\n",
    "        if (w != 0):\n",
    "            change_rating = 0\n",
    "            for change in range(samples):\n",
    "                new_x = copy.deepcopy(x)\n",
    "                new_x[i] = new_x[i] + (100 * change / samples)\n",
    "                if (model(np.array([x])) != model(np.array([new_x]))):\n",
    "                    change_rating += 1/samples\n",
    "\n",
    "            if (change_rating > samples * 3 / 4):\n",
    "                keywords.append((i, w))\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compactness(keywords, explanation, num_words):\n",
    "    \"\"\"\n",
    "    explanation: the feature attributions\n",
    "    \"\"\"\n",
    "    explanation = explanation[:num_words]\n",
    "    q0, q4 = np.percentile(explanation, [0, 100])\n",
    "    iqr = q4 - q0\n",
    "    upper_bound = q4 - (0.4 * iqr)\n",
    "    outliers = len([x for x in explanation if x > upper_bound])\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(keywords, explanation, num_words):\n",
    "    \"\"\"\n",
    "    keywords: the list of keywords + their indices\n",
    "    explanation: the feature attributions\n",
    "    \"\"\"\n",
    "    explanation = explanation[:num_words]\n",
    "    q0, q4 = np.percentile(explanation, [0, 100])\n",
    "    iqr = q4 - q0\n",
    "    upper_bound = q4 - (0.4 * iqr)\n",
    "    result = 0\n",
    "    for (index, word) in keywords:\n",
    "        if explanation[index] > upper_bound:\n",
    "            result += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuance(explanation, num_words):\n",
    "    \"\"\"\n",
    "    explanation: the feature attributions\n",
    "    \"\"\"\n",
    "    explanation = explanation[:num_words]\n",
    "    if (np.max(explanation) == np.min(explanation)):\n",
    "        return 1\n",
    "    return 1 - np.std(explanation)/np.std([np.max(explanation), np.min(explanation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(words, ids, model, positive_words, negative_words, explanation):\n",
    "    num_words = np.sum(np.array(words) != \"[PAD]\")\n",
    "    keywords = []\n",
    "    keywords += realism(words, positive_words, negative_words, model(np.array([ids])), num_words)\n",
    "    fid_words = fidelity(ids, model, num_words)\n",
    "    keywords += fid_words\n",
    "    print(\"fidelity words:\", fid_words)\n",
    "    quality = None\n",
    "    print(\"Keywords\", keywords)\n",
    "    print(num_words)\n",
    "\n",
    "    if len(keywords) > 0:\n",
    "        if (compactness(keywords, explanation, num_words) == 0):\n",
    "            quality = 0\n",
    "        else:\n",
    "            quality = correctness(keywords, explanation, num_words) * correctness(keywords, explanation, num_words) / compactness(keywords, explanation, num_words) / len(keywords)\n",
    "    else:\n",
    "        quality = nuance(explanation, num_words)\n",
    "\n",
    "    print(\"Compactness\", compactness(keywords, explanation, num_words))\n",
    "    print(\"Correctness\", correctness(keywords, explanation, num_words))\n",
    "    print(\"Nuance\", nuance(explanation, num_words))\n",
    "    return quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
